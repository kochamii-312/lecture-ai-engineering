# main.py
import streamlit as st
import pandas as pd
import os as os
from visualize import show_all_visualizations
from preprocess import merge_comment_columns
from lecture_analyzer import LectureAnalyzer
from dotenv import load_dotenv
from typing import List, Tuple
import plotly.express as px
import plotly.graph_objects as go

load_dotenv()
HF_TOKEN = os.getenv("HUGGINGFACE_TOKEN")

headers = {"Authorization": f"Bearer {HF_TOKEN}"}

def display_results(results):
    """
    åˆ†æçµæœã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    
    Args:
        results (AnalysisResults): åˆ†æçµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    st.header("ğŸ“Š åˆ†æçµæœ")
    
    # æ¦‚è¦çµ±è¨ˆã‚’è¡¨ç¤º
    display_summary_stats(results)
    
    # æ„Ÿæƒ…åˆ†æçµæœ
    st.subheader("ğŸ˜Š æ„Ÿæƒ…åˆ†æçµæœ")
    display_sentiment_analysis(results)
    
    st.divider()
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ†æçµæœ
    st.subheader("ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªåˆ†æçµæœ")
    display_category_analysis(results)
    
    st.divider()
    
    # å±é™ºã‚³ãƒ¡ãƒ³ãƒˆæ¤œå‡ºçµæœ
    st.subheader("âš ï¸ å±é™ºã‚³ãƒ¡ãƒ³ãƒˆæ¤œå‡ºçµæœ")
    display_dangerous_comments(results)

def display_summary_stats(results):
    """æ¦‚è¦çµ±è¨ˆã®è¡¨ç¤º"""
    total_comments = (
        len(results.positive_comments) + 
        len(results.negative_comments) + 
        len(results.neutral_comments)
    )
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°", total_comments)
    
    with col2:
        st.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–", len(results.positive_comments))
    
    with col3:
        st.metric("ãƒã‚¬ãƒ†ã‚£ãƒ–", len(results.negative_comments))
    
    with col4:
        st.metric("å±é™ºã‚³ãƒ¡ãƒ³ãƒˆ", len(results.dangerous_comments))

def display_sentiment_analysis(results):
    """æ„Ÿæƒ…åˆ†æçµæœã®è¡¨ç¤º"""
    # æ„Ÿæƒ…åˆ†å¸ƒã®å††ã‚°ãƒ©ãƒ•
    sentiment_counts = {
        "ãƒã‚¸ãƒ†ã‚£ãƒ–": len(results.positive_comments),
        "ãƒã‚¬ãƒ†ã‚£ãƒ–": len(results.negative_comments),
        "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«": len(results.neutral_comments)
    }
    
    # Plotlyã§å††ã‚°ãƒ©ãƒ•ä½œæˆ
    fig = px.pie(
        values=list(sentiment_counts.values()),
        names=list(sentiment_counts.keys()),
        title="æ„Ÿæƒ…åˆ†å¸ƒ",
        color_discrete_map={
            "ãƒã‚¸ãƒ†ã‚£ãƒ–": "#28a745",
            "ãƒã‚¬ãƒ†ã‚£ãƒ–": "#dc3545", 
            "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«": "#6c757d"
        }
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # è©³ç´°è¡¨ç¤ºç”¨ã®ã‚¿ãƒ–
    tab1, tab2, tab3 = st.tabs(["ğŸ‘ ãƒã‚¸ãƒ†ã‚£ãƒ–", "ğŸ‘ ãƒã‚¬ãƒ†ã‚£ãƒ–", "ğŸ˜ ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"])
    
    with tab1:
        display_comment_list("ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚³ãƒ¡ãƒ³ãƒˆ", results.positive_comments, "success")
    
    with tab2:
        display_comment_list("ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚³ãƒ¡ãƒ³ãƒˆ", results.negative_comments, "error")
    
    with tab3:
        display_comment_list("ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ", results.neutral_comments, "info")

def display_category_analysis(results):
    """ã‚«ãƒ†ã‚´ãƒªåˆ†æçµæœã®è¡¨ç¤º"""
    category_counts = {
        "è¬›ç¾©å†…å®¹": len(results.lecture_content_comments),
        "è¬›ç¾©è³‡æ–™": len(results.lecture_materials_comments),
        "é‹å–¶": len(results.operation_comments),
        "ãã®ä»–": len(results.other_comments)
    }
    
    # æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º
    fig = px.bar(
        x=list(category_counts.keys()),
        y=list(category_counts.values()),
        title="ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚³ãƒ¡ãƒ³ãƒˆæ•°",
        labels={"x": "ã‚«ãƒ†ã‚´ãƒª", "y": "ã‚³ãƒ¡ãƒ³ãƒˆæ•°"},
        color=list(category_counts.values()),
        color_continuous_scale="viridis"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°è¡¨ç¤º
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“š è¬›ç¾©å†…å®¹", "ğŸ“„ è¬›ç¾©è³‡æ–™", "âš™ï¸ é‹å–¶", "ğŸ“ ãã®ä»–"])
    
    with tab1:
        display_comment_list("è¬›ç¾©å†…å®¹ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ", results.lecture_content_comments)
    
    with tab2:
        display_comment_list("è¬›ç¾©è³‡æ–™ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ", results.lecture_materials_comments)
    
    with tab3:
        display_comment_list("é‹å–¶ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ", results.operation_comments)
    
    with tab4:
        display_comment_list("ãã®ä»–ã®ã‚³ãƒ¡ãƒ³ãƒˆ", results.other_comments)

def display_dangerous_comments(results):
    """å±é™ºã‚³ãƒ¡ãƒ³ãƒˆã®è¡¨ç¤º"""
    if len(results.dangerous_comments) == 0:
        st.success("âœ… å±é™ºãªã‚³ãƒ¡ãƒ³ãƒˆã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    st.warning(f"âš ï¸ {len(results.dangerous_comments)}ä»¶ã®å±é™ºãªå¯èƒ½æ€§ã®ã‚ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚")
    
    for i, (comment, score) in enumerate(results.dangerous_comments, 1):
        with st.expander(f"å±é™ºã‚³ãƒ¡ãƒ³ãƒˆ #{i} (ã‚¹ã‚³ã‚¢: {score:.2f})"):
            st.text(comment)
            
            # å±é™ºåº¦ã«å¿œã˜ã¦è‰²åˆ†ã‘
            if score > 0.9:
                st.error("âš ï¸ é«˜ãƒªã‚¹ã‚¯")
            elif score > 0.8:
                st.warning("âš ï¸ ä¸­ãƒªã‚¹ã‚¯")
            else:
                st.info("âš ï¸ ä½ãƒªã‚¹ã‚¯")

def display_comment_list(title, comments, message_type="info"):
    """ã‚³ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã®è¡¨ç¤º"""
    if not comments:
        st.info("è©²å½“ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    st.write(f"**{title}** ({len(comments)}ä»¶)")
    
    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ
    items_per_page = 10
    total_pages = (len(comments) + items_per_page - 1) // items_per_page
    
    if total_pages > 1:
        page = st.selectbox(
            "ãƒšãƒ¼ã‚¸ã‚’é¸æŠ", 
            range(1, total_pages + 1), 
            key=f"page_{title}"
        )
        start_idx = (page - 1) * items_per_page
        end_idx = min(start_idx + items_per_page, len(comments))
        display_comments = comments[start_idx:end_idx]
    else:
        display_comments = comments[:items_per_page]
    
    for i, comment in enumerate(display_comments, 1):
        if message_type == "success":
            st.success(f"{i}. {comment}")
        elif message_type == "error":
            st.error(f"{i}. {comment}")
        elif message_type == "warning":
            st.warning(f"{i}. {comment}")
        else:
            st.info(f"{i}. {comment}")

def display_cluster_results(comments, title, embedder=None):
    """
    ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®è¡¨ç¤ºï¼ˆæ—¢å­˜ã®cluster_and_rankæ©Ÿèƒ½ã‚’æ´»ç”¨ï¼‰
    
    Args:
        comments: ã‚³ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
        title: è¡¨ç¤ºã‚¿ã‚¤ãƒˆãƒ«
        embedder: CommentEmbedder ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    if not comments or len(comments) < 3:
        st.info(f"{title}: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ååˆ†ãªã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    st.subheader(f"ğŸ” {title} - ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ")
    
    if embedder is None:
        # ç°¡å˜ãªé »å‡ºèªåˆ†æã§ä»£æ›¿
        display_word_frequency(comments, title)
        return
    
    try:
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        cluster_results = embedder.cluster_and_rank(comments, n_clusters=min(5, len(comments)//2))
        
        for i, (count, representative) in enumerate(cluster_results, 1):
            with st.expander(f"ã‚¯ãƒ©ã‚¹ã‚¿ {i}: {count}ä»¶"):
                st.write(f"**ä»£è¡¨ã‚³ãƒ¡ãƒ³ãƒˆ:** {representative}")
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§ä»¶æ•°ã‚’è¦–è¦šåŒ–
                st.progress(count / len(comments))
                
    except Exception as e:
        st.error(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        display_word_frequency(comments, title)

def display_word_frequency(comments, title):
    """ç°¡å˜ãªé »å‡ºèªåˆ†æ"""
    from collections import Counter
    import re
    
    # ç°¡å˜ãªæ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆæœ¬æ ¼çš„ã«ã¯MeCabãªã©ã‚’ä½¿ç”¨ï¼‰
    all_words = []
    for comment in comments:
        # ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã‚’æŠ½å‡º
        words = re.findall(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠæ¼¢å­—]+', comment)
        all_words.extend([w for w in words if len(w) > 1])
    
    word_freq = Counter(all_words)
    top_words = word_freq.most_common(10)
    
    if top_words:
        st.write(f"**{title} - é »å‡ºèªTOP10**")
        for word, count in top_words:
            st.write(f"- {word}: {count}å›")

def main():
    st.title("ğŸ“Š æ¾å°¾ç ”è¬›ç¾©ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆåˆ†æã‚¢ãƒ—ãƒª")
    
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº† ({len(df)}è¡Œ)")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            with st.expander("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                st.dataframe(df.head())
            
            if st.button("ğŸš€ åˆ†æé–‹å§‹"):
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # åˆ†æå®Ÿè¡Œ
                analyzer = LectureAnalyzer(HF_TOKEN)
                
                progress_bar.progress(20)
                status_text.text("ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
                
                results = analyzer.analyze(df)
                
                progress_bar.progress(100)
                status_text.text("åˆ†æå®Œäº†!")
                
                if results:
                    # çµæœè¡¨ç¤º
                    display_results(results)
                    
                    # CSVå‡ºåŠ›
                    csv_file = results.export_csv()
                    with open(csv_file, 'rb') as f:
                        st.download_button(
                            "ğŸ“¥ çµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            f.read(),
                            file_name=csv_file,
                            mime="text/csv"
                        )
                
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
