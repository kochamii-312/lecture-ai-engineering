# main.py

import matplotlib.font_manager
import streamlit as st
import os
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import japanize_matplotlib
from dotenv import load_dotenv
from preprocess import split_into_sentences
from labeling import get_sentiment_label, get_category_label
from clustering import summarize_comments, cluster_comments
from importance import score_specificity, score_urgency, score_commonality, score_importance, get_cluster_number, get_cluster_size_and_total
from danger import extract_dangerous_comments

# matplotlib.font_manager._rebuild()
# matplotlib.rcParams['font.family'] = 'IPAexGothic'

load_dotenv()
HF_TOKEN = os.getenv("HUGGINGFACE_TOKEN")

headers = {"Authorization": f"Bearer {HF_TOKEN}"}

def main():

    st.title("ğŸ“Š è¬›ç¾©ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆåˆ†æã‚¢ãƒ—ãƒª")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“„ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨åˆ†æ", "ğŸ˜Š ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†é¡", "ğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ†é¡", "ğŸš¨ é‡è¦åº¦ã‚¹ã‚³ã‚¢"])
    with tab1:
        st.sidebar.header("â„¹ï¸ ã“ã®ã‚¢ãƒ—ãƒªã®ã‚¬ã‚¤ãƒ‰")
        st.sidebar.info("è¬›ç¾©ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã®excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€é‡è¦ãªã‚³ãƒ¡ãƒ³ãƒˆã‚„å±é™ºåº¦ã®é«˜ã„ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã—ã¾ã™ã€‚")

        pos_limit = st.slider("è¡¨ç¤ºã™ã‚‹ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚³ãƒ¡ãƒ³ãƒˆæ•°", 1, 20, 10)
        neg_limit = st.slider("è¡¨ç¤ºã™ã‚‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚³ãƒ¡ãƒ³ãƒˆæ•°", 1, 20, 10)
        cat_limit = st.slider("ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®è¡¨ç¤ºæ•°", 1, 20, 10)
        
        uploaded_file = st.file_uploader("excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx", "xls"], key="excel_upload") # keyå¼•æ•°ã§æ˜ç¤ºçš„ã«è­˜åˆ¥å­ã‚’æŒ‡å®š
        if uploaded_file:
            if uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
                df = pd.read_excel(uploaded_file)    
            elif uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                st.error("âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚Excelã¾ãŸã¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            
            st.write("ğŸ‘€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
            st.dataframe(df.head())
            
            # ã‚«ãƒ©ãƒ åã®å¤‰æ›´
            current_columns = df.columns.tolist()
            new_column_names_part = ['comment1_positive', 'comment2_negative', 'comment3_about_teacher', 'comment4_future_suggestions', 'comment5_free']
            current_columns[16:21] = new_column_names_part
            df.columns = current_columns

            if st.button("ğŸš€ åˆ†æã™ã‚‹"):
                progress = st.progress(0, text="åˆ†æã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...")
                positive_comment_list = []
                negative_comment_list = []
                
                lecture_content_comment_list = []
                lecture_materials_comment_list = []
                operation_comment_list = []
                others_comment_list = []
                comment_columns_all = new_column_names_part
                
                progress.progress(10, "ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²ãƒ»æ„Ÿæƒ…åˆ†æä¸­...")
                # 'comment1_positive'ã‚«ãƒ©ãƒ ã‹ã‚‰è¦ç´ ã‚’å–å¾—ã—ã€positive_comment_listã«è¿½åŠ 
                if 'comment1_positive' in df.columns:
                    positive_comments_from_df = df['comment1_positive'].tolist()
                    positive_comment_list.extend(split_into_sentences(positive_comments_from_df))
                    print("\n positive_comment_list:")
                    print(positive_comment_list)
                else:
                    print("\n'comment1_positive' column not found in the DataFrame.")
                # 'comment2_negative'ã‚«ãƒ©ãƒ ã‹ã‚‰è¦ç´ ã‚’å–å¾—ã—ã€negative_comment_listã«è¿½åŠ 
                if 'comment2_negative' in df.columns:
                    negative_comments_from_df = df['comment2_negative'].tolist()
                    positive_comment_list.extend(split_into_sentences(negative_comments_from_df))
                    print("\n negative_comment_list:")
                    print(negative_comment_list)
                else:
                    print("\n'comment2_negative' column not found in the DataFrame.")
                
                # æ®‹ã‚Šã®ã‚«ãƒ©ãƒ ã®æ„Ÿæƒ…åˆ†é¡
                comment_columns = ['comment3_about_teacher', 'comment4_future_suggestions', 'comment5_free']
                for col in comment_columns:
                    print(f"\nProcessing column: {col}")
                    splited_sentences = split_into_sentences(df[col].dropna().tolist())
                    for index, comment_text in enumerate(splited_sentences):
                        sentiment = get_sentiment_label(comment_text)
                        print(f"Row {index}: '{comment_text}' -> Sentiment: {sentiment}")
                        if sentiment == 'positive':
                            positive_comment_list.append(comment_text)
                        elif sentiment == 'negative':
                            negative_comment_list.append(comment_text)
                
                print(f"\n positive_comment_list: {positive_comment_list}, ä»¶æ•°: {len(positive_comment_list)})")
                print(f"\n negative_comment_list: {negative_comment_list}, ä»¶æ•°: {len(negative_comment_list)})")
                
                # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
                progress.progress(30, "ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ä¸­...")
                for col in comment_columns_all:
                    print(f"\nProcessing column: {col}")
                    splited_sentences = split_into_sentences(df[col].dropna().tolist())
                    for index, comment_text in enumerate(splited_sentences):
                        category = get_category_label(comment_text)
                        print(f"Row {index}: '{comment_text}' -> Category: {category}")
                        if category == 'è¬›ç¾©å†…å®¹':
                            lecture_content_comment_list.append(comment_text)
                        elif category == 'è¬›ç¾©è³‡æ–™':
                            lecture_materials_comment_list.append(comment_text)
                        elif category == 'é‹å–¶':
                            operation_comment_list.append(comment_text)
                        else:
                            others_comment_list.append(comment_text)
                print(f"\n lecture_content_comment_list: {lecture_content_comment_list}, ä»¶æ•°: {len(lecture_content_comment_list)})")
                print(f"\n lecture_materials_comment_list: {lecture_materials_comment_list}, ä»¶æ•°: {len(lecture_materials_comment_list)})")
                print(f"\n operation_comment_list: {operation_comment_list}, ä»¶æ•°: {len(operation_comment_list)})")
                print(f"\n others_comment_list: {others_comment_list}, ä»¶æ•°: {len(others_comment_list)})")
                
                # é‡è¦ã‚¹ã‚³ã‚¢
                progress.progress(60, "é‡è¦åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—ä¸­...")
                scored_comments_all = []

                for col in comment_columns_all:
                    comments = df[col].dropna().tolist()
                    splited_sentences = split_into_sentences(comments)
                    clustered = cluster_comments(splited_sentences)
                    for index, comment_text in enumerate(splited_sentences):
                        spec = score_specificity(comment_text)
                        urg = score_urgency(comment_text)
                        cluster_number = get_cluster_number(comment_text, clustered)
                        cluster_size, total_comments = get_cluster_size_and_total(cluster_number, clustered)
                        comm = score_commonality(cluster_size, total_comments)
                        importance_score = score_importance(spec, urg, comm)

                        print(f"Row {index}: '{comment_text}' -> Specificity: {spec}, Urgency: {urg}, Commonality: {comm}, Importance Score: {importance_score}")

                        # è¾æ›¸å½¢å¼ã§ã¾ã¨ã‚ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ 
                        scored_comments_all.append({
                            "comment": comment_text,
                            "specificity": spec,
                            "urgency": urg,
                            "commonality": comm,
                            "importance_score": importance_score,
                            "cluster": cluster_number
                        })

                progress.progress(90, "å±é™ºã‚³ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡ºä¸­...")
                all_comments = sum([split_into_sentences(df[col].dropna().tolist()) for col in comment_columns_all], [])
                dangerous_comments = extract_dangerous_comments(all_comments)

                progress.progress(100, "åˆ†æå®Œäº†ï¼")
                st.success("ğŸ‰ åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚å„ã‚¿ãƒ–ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.balloons()

                # åˆ†æçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.update({
                    'positive_summary': summarize_comments(positive_comment_list, pos_limit),
                    'negative_summary': summarize_comments(negative_comment_list, neg_limit),
                    'lecture_content_summary': summarize_comments(lecture_content_comment_list, cat_limit),
                    'lecture_materials_summary': summarize_comments(lecture_materials_comment_list, cat_limit),
                    'operation_summary': summarize_comments(operation_comment_list, cat_limit),
                    'others_summary': summarize_comments(others_comment_list, cat_limit),
                    'scored_comments_df': pd.DataFrame(scored_comments_all).sort_values(by='importance_score', ascending=False),
                    'dangerous_comments': dangerous_comments,
                    'sentiment_counts': {
                        'ãƒã‚¸ãƒ†ã‚£ãƒ–': len(positive_comment_list),
                        'ãƒã‚¬ãƒ†ã‚£ãƒ–': len(negative_comment_list)
                    },
                    'category_counts': {
                        'è¬›ç¾©å†…å®¹': len(lecture_content_comment_list),
                        'è¬›ç¾©è³‡æ–™': len(lecture_materials_comment_list),
                        'é‹å–¶': len(operation_comment_list),
                        'ãã®ä»–': len(others_comment_list)
                    }
                })

            
    if 'positive_summary' in st.session_state:
        with tab2:
            # ãƒã‚¸ãƒã‚¬ã®è¦ç´„
            st.subheader("âœ… ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚³ãƒ¡ãƒ³ãƒˆè¦ç´„")
            for i, comment in enumerate(st.session_state['positive_summary'], 1):
                st.write(f"{i}. {comment}")

            st.subheader("âš ï¸ ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚³ãƒ¡ãƒ³ãƒˆè¦ç´„")
            for i, comment in enumerate(st.session_state['negative_summary'], 1):
                st.write(f"{i}. {comment}")

            st.subheader("ğŸ“Š æ„Ÿæƒ…åˆ†å¸ƒï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰")
            fig, ax = plt.subplots()
            labels = list(st.session_state['sentiment_counts'].keys())
            sizes = list(st.session_state['sentiment_counts'].values())
            plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
            ax.axis('equal')
            st.pyplot(fig)

        with tab3:
            # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®è¦ç´„
            st.subheader("ğŸ“˜ è¬›ç¾©å†…å®¹ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ")
            for i, comment in enumerate(st.session_state['lecture_content_summary'], 1):
                st.write(f"{i}. {comment}")
            st.subheader("ğŸ“— è¬›ç¾©è³‡æ–™ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ")
            for i, comment in enumerate(st.session_state['lecture_materials_summary'], 1):
                st.write(f"{i}. {comment}")
            st.subheader("ğŸ“™ é‹å–¶ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ")
            for i, comment in enumerate(st.session_state['operation_summary'], 1):
                st.write(f"{i}. {comment}")

            st.subheader("ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰")
            fig2, ax2 = plt.subplots()
            labels = list(st.session_state['category_counts'].keys())
            sizes = list(st.session_state['category_counts'].values())
            ax2.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
            ax2.axis('equal')
            st.pyplot(fig2)

        with tab4:
            #é‡è¦åº¦ã‚¹ã‚³ã‚¢ä¸Šä½10ä»¶
            st.subheader("ğŸ† é‡è¦åº¦ã‚¹ã‚³ã‚¢ä¸Šä½ã‚³ãƒ¡ãƒ³ãƒˆ")
            top_10 = st.session_state['scored_comments_df'].head(10)
            for _, row in top_10.iterrows():
                category = get_category_label(row['comment'])
                with st.expander(row['comment'][:40] + "..."):
                    st.write(f"ã‚³ãƒ¡ãƒ³ãƒˆå…¨æ–‡: {row['comment']}")
                    st.markdown(f"- ã‚«ãƒ†ã‚´ãƒª: **{category}**")
                    st.markdown(f"- å…·ä½“æ€§: {row['specificity']} / 1.0")
                    st.markdown(f"- ç·Šæ€¥æ€§: {row['urgency']} / 1.0")
                    st.markdown(f"- å…±é€šæ€§: {row['commonality']:.2f} / 1.0")
                    st.markdown("""
                    <style>
                    .big-font {
                        font-size:20px ï¼important;
                        font-weight: bold;
                        color: #0066cc;
                    }
                    </style>
                    """, unsafe_allow_html=True)
                    st.markdown(f'<p class="big-font">- é‡è¦åº¦ã‚¹ã‚³ã‚¢: {row['importance_score']} / 10</p>', unsafe_allow_html=True)
                    
            st.subheader("ğŸ“ˆ é‡è¦åº¦ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
            fig3, ax3 = plt.subplots()
            st.session_state['scored_comments_df']['importance_score'].hist(bins=20, ax=ax3)
            ax3.set_xlabel("é‡è¦åº¦ã‚¹ã‚³ã‚¢")
            ax3.set_ylabel("ä»¶æ•°")
            st.pyplot(fig3)
            
            # å±é™ºã‚³ãƒ¡ãƒ³ãƒˆã®æŠ½å‡º
            st.subheader("ğŸš¨ å±é™ºã‚³ãƒ¡ãƒ³ãƒˆ")
            if st.session_state['dangerous_comments']:
                for i, comment in enumerate(st.session_state['dangerous_comments'], 1):
                    st.write(f"{i}. {comment}")
            else:
                st.info("å±é™ºã‚³ãƒ¡ãƒ³ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()